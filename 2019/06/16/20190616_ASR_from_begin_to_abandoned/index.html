<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>语音识别从入门到放弃 | xuxping</title><link rel="stylesheet" type="text/css" href="../../../../css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="../../../../favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="../../../../favicon.ico"><link rel="apple-touch-icon" href="../../../../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../../../../apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">语音识别从入门到放弃</h1><a id="logo" href="../../../../.">xuxping</a><p class="description">一点一滴积累</p></div><div id="nav-menu"><a class="current" href="../../../../."><i class="fa fa-home"> 首页</i></a><a href="../../../../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../../../../about/"><i class="fa fa-user"> 关于</i></a><a href="../../../../atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">语音识别从入门到放弃</h1><div class="post-meta">2019-06-16<span> | </span><span class="category"><a href="../../../../categories/AI/">AI</a></span></div><div class="post-content"><p>语音识别是将语音信号转换为文字。语音识别应用广泛，如智能音箱，语音搜索，语音交互等。语音识别技术的研究已经超过半个世纪，从简单的语音片段匹配，孤立词的识别到基于统计模型和概率的HMM-GMM以及连续语音识别，目前已经发展到了用深度学习构建端到端的语音识别系统。</p>
<blockquote>
<p>本文只是对使用Kaldi做语音识别的作业进行一个总结，并不会涉及太多原理的（我也不懂）。本文很多内容直接参考或借鉴了很多网上的资料，相当于做了一个整合，最后结合一个kaldi实践例子。  </p>
</blockquote>
<span id="more"></span>
<p>语言由单词word组成，单词由音素phone组成 。语音变成文字的大致流程为：将一段语音的声波<strong>按帧切开</strong>，<strong>用帧组成状态</strong>，<strong>用状态组成音素</strong>，<strong>再将音素合成单词</strong>，语音就变成了文字 。<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/C959D670-F598-419B-AB2D-B8C7CC234107.png"></p>
<h1 id="典型的语音识别系统组成"><a href="#典型的语音识别系统组成" class="headerlink" title="典型的语音识别系统组成"></a>典型的语音识别系统组成</h1><p>如下图所示，做一个完整的语音识别系统一般由前后端两大模块组成。<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/v2-bedbc1fceaeab88133f1b9294c224ef4_r.jpg"></p>
<ul>
<li>特征提取负责将从语音信号中提取特征，用于建立识别模型</li>
<li>声学模型负责在语音特征和音素之间建立映射，将语音转化为音素</li>
<li>语言模型用于判断什么样的句子「像话」，什么样的句子「不像话」</li>
<li>解码器用于在海量的句子中快速找到比较好的识别结果</li>
</ul>
<p>参考资料：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/24342192/answer/225984574">如何入门语音识别？ - 知乎</a></p>
<p>下面部分将对每个模块进行介绍。</p>
<h2 id="语音特征提取"><a href="#语音特征提取" class="headerlink" title="语音特征提取"></a>语音特征提取</h2><p>语音信号是连续不断的值，无法直接用于建模，当然现在火热的DNN模型已经不需要提取特征啥的。MFCC特征（梅尔频率倒谱系数）是一种在自动语音和说话人识别中广泛使用的特征。主要提取流程如下：<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/0951CBDE-22A6-44FF-A645-C62DBC85BF14.png">  </p>
<ol>
<li>对语音进行预加重、分帧和加窗；（加强语音信号性能（信噪比，处理精度等）的一些预处理）</li>
<li>对每一个短时分析窗，通过快速傅里叶变化FFT得到对应的频谱；（获得分布在时间轴上不同时间窗内的频谱）</li>
<li>将上面的频谱通过Mel滤波器组得到Mel频谱；（通过Mel频谱，将线形的自然频谱转换为体现人类听觉特性的Mel频谱）</li>
<li>在Mel频谱上面进行倒谱分析（取对数，做逆变换，实际逆变换一般是通过DCT离散余弦变换来实现，取DCT后的第2个到第13个系数作为MFCC系数），获得Mel频率倒谱系数MFCC，这个MFCC就是这帧语音的特征；（倒谱分析，获得MFCC作为语音特征）</li>
</ol>
<p>最终语音就可以通过一系列的倒谱向量来描述了，每个向量就是每帧的MFCC特征向量。当日还有FilterBank(fbank)也是一种提取特征的方法，没有做过log和DCT的就是fbank特征。<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/1F8520F2-F108-4874-BD31-F7DFBDD586AE.png"></p>
<p><strong>参考资料</strong><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/BaroC/p/4283380.html">梅尔频率倒谱系数（MFCC） 学习笔记 - BaroC - 博客园</a><br>MFCC Guide <a target="_blank" rel="noopener" href="http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">Practical Cryptography</a><br>MFCC Python实现  <a target="_blank" rel="noopener" href="https://github.com/jameslyons/python_speech_features">https://github.com/jameslyons/python_speech_features</a> </p>
<h2 id="HMM-GMM"><a href="#HMM-GMM" class="headerlink" title="HMM-GMM"></a>HMM-GMM</h2><p>语音识别中，标注只是针对整段音频的，而不是针对每一帧；语音识别是针对每个音素都建立一个HMM模型，而不是所有音素用一个HMM模型描述。</p>
<ul>
<li>字级别的标注</li>
<li>音素级别的标注，音素级别的标注工作量很大，可以通过发音词典，将字级别的标注转换成音素级别的标注，这种转换没办法消除多音字的影响，但实际上不会对结果产生太大影响<br>以“你好，ni hao”为例<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/v2-c28d72e908d34e94c31289a9445eb77e_r.jpg"><br><strong>对”n“、”i2“、”h“、”ao3“对应的HMM-GMM模型进行训练，得到模型参数</strong>，<strong>自环</strong>可以对任意长的音频建模，这也是连续语音识别的基础。</li>
<li>HMM-GMM模型的参数(转移概率、高斯分布的均值、方差)<ol>
<li>转移概率</li>
<li>发射概率：因为我们使用GMM对发射概率建模，所以<strong>实际参数就是高斯分布中的均值和方差</strong></li>
</ol>
</li>
<li>模型的输入： 每帧信号的MFCC特征(也可以是fbank，plp等)，通常取39维的MFCC特征</li>
<li>模型的输出：每一帧属于”n”、”i2”、”h”、”ao3”中的某一个状态</li>
</ul>
<p><strong>HMM-GMM模型的学习过程并不是”有监督的“</strong>，音频只告诉我们对应的标注是”n”、”i2”、”h”、”ao3”，并没有告诉我们每一帧(即每一个输入)对应的label是啥。对于这种无监督的任务，我们EM算法来进行训练。<br>训练步骤：</p>
<ol>
<li>初始化对齐。以上面的20秒音频为例，因为我们不知道每一帧对应哪个声韵母的某个状态，所以就均分。以上面的20秒音频为例，因为我们不知道每一帧对应哪个声韵母的某个状态，所以就均分。也就是说1-5帧对应”n”，6-10帧对应”i2”，11-15帧对应”h”，16-20帧对应”ao3”。同时”n”又有三个状态，那么就把1-2帧分给状态①，3-4帧分给状态②，第5帧分给状态③。”i2”、”h”、”ao3”亦如此。<img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/v2-1f3b55b94a5dfe01cf55290c53a49d3f_r.jpg"></li>
<li>更新模型参数</li>
<li>转移概率：通过上图，我们可以得到①-&gt;①的转移次数，①-&gt;②的转移次数等等。然后除以总的转移次数，就可以得到每种转移的概率，这是一个统计的过程</li>
<li>发射概率：即均值和方差。以状态①的均值和方差为例，由上图我们可以知道第1帧和第2帧对应状态①。假设第1帧的MFCC特征是(4,3)，第2帧的MFCC特征的MFCC特征是(4,7)。那么状态①的均值就是(4,5)，方差是(0,8)</li>
<li>step3：重新对齐。根据step2得到的参数，重新对音频进行状态级别的对齐。这一步区别于step1的初始化，step1的初始化我们是采用粗暴的均匀对齐，而这一步的对齐是根据step2的参数进行对齐的。这里的对齐方法有两种：a、硬对齐：采用维特比算法；b、软对齐：采用前后向算法<img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/v2-d875d58274be1d05a9bbc1638e1867bd_r.jpg"></li>
<li>重复step2和step3多次，直到收敛。</li>
</ol>
<p>参考材料：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/63753017">语音识别中的HMM-GMM模型：从一段语音说起 - 知乎</a></p>
<h2 id="如何评估语音识别的准确率"><a href="#如何评估语音识别的准确率" class="headerlink" title="如何评估语音识别的准确率"></a>如何评估语音识别的准确率</h2><p>字错误率WER(WordError Rate)，<code>WER=(I+D+S)/N</code>，其中I代表被插入的单词个数，D代表被删除的单词个数，S代表被替换的单词个数。也就是说把识别出来的结果中，多认的，少认的，认错的全都加起来，除以总单词数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%WER 0.00 [ 0 / 232, 0 ins, 0 del, 0 sub ]</span><br></pre></td></tr></table></figure>
<p><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/95373E78-A2DD-446C-8B1B-517E01BCB20A.png"></p>
<p>有了前面的一些基础知识就可以进入实践踩坑环节。</p>
<h1 id="使用kaldi-thchs30进行实践"><a href="#使用kaldi-thchs30进行实践" class="headerlink" title="使用kaldi+thchs30进行实践"></a>使用kaldi+thchs30进行实践</h1><p><a target="_blank" rel="noopener" href="http://kaldi-asr.org/">Kaldi ASR</a>是一个使用广泛的语言识别工具，能够快速帮助初学者建立起一个可用的语言识别系统。入门难度还是挺大，涉及到shell，C++，Python，Perl以及众多的让人眼花缭乱的脚本，很容易让人放弃，做完这个作业我就打算放弃了。如何安装编译kaldi参考源码目录下的<code>INSTALL</code>文件，我在ubuntu18.04上安装的，遇到的问题基本都是系统库没有。</p>
<p>THCHS30 <a target="_blank" rel="noopener" href="http://www.openslr.org/18/">http://www.openslr.org/18/</a> ， 清华大学开源的免费的中文语音识别数据，数据集划分如下：<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/794A1BC5-E63F-483F-ACD9-0AF4322272B3.png"></p>
<p>下面先对kaldi的egs目录下的thchs30中的脚本进行熟悉，然后才能开始干活。</p>
<h2 id="thchs30处理脚本解析"><a href="#thchs30处理脚本解析" class="headerlink" title="thchs30处理脚本解析"></a>thchs30处理脚本解析</h2><p>用kaldi做模型基本都遵循同样的套路，<code>run.sh</code>这个文件包含了数据预处理，特征提取，模型建立的流程，理解了这个文件后面就好办了，下面主要对其中的关键部分进行说明。</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>生成word.txt（词序列），phone.txt（音素序列），text（与word.txt相同），wav.scp（语音），utt2pk（句子与说话人的映射），spk2utt（说话人与句子的映射）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">local/thchs-30_data_prep.sh $H $thchs/data_thchs30 || exit 1;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/DF782B4A-4B05-4311-953A-F6F1B9927C32.png"></p>
<ul>
<li>word.txt：音频标注的文本<img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/57141966-E711-412E-B70F-4124CC3B4DF7.png"></li>
<li>wav.scp：对应说话人和音频的地址<img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/4CE875EC-A3AE-4DBF-8F48-2DFD117B7475.png"></li>
<li>phone.txt：对应标注的音素序列<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/01B773E6-0E2A-4DB2-B523-2C017DBC1D7D.png"></li>
<li>spk2utt：说话人和其音频对应关系，如C32这个人，后面是他声音的音频 , utt2spk则是音频和说话人的对应<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/98FF2C98-E717-4D88-BF5E-720B7538706E.png"></li>
</ul>
<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><ol>
<li>重建data&#x2F;mfcc目录，然后将train,dev,test,test_phone拷贝到该目录下</li>
<li>分别提取 train dev test 的MFCC特征，并进行均值和归一化cmvn(不是必须)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#produce MFCC features</span><br><span class="line">rm -rf data/mfcc &amp;&amp; mkdir -p data/mfcc &amp;&amp;  cp -R data/&#123;train,dev,test,test_phone&#125; data/mfcc || exit 1;</span><br><span class="line">for x in train dev test; do</span><br><span class="line">   #make  mfcc</span><br><span class="line">	# data/mfcc/$x exp/make_mfcc/$x mfcc/$x 分别表示数据目录，日志目录，最终提取的特征目录</span><br><span class="line">   steps/make_mfcc.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/$x exp/make_mfcc/$x mfcc/$x || exit 1;</span><br><span class="line">   #compute cmvn</span><br><span class="line">   steps/compute_cmvn_stats.sh data/mfcc/$x exp/mfcc_cmvn/$x mfcc/$x || exit 1;</span><br><span class="line">done</span><br><span class="line">#copy feats and cmvn to test.ph, avoid duplicated mfcc &amp; cmvn</span><br><span class="line">cp data/mfcc/test/feats.scp data/mfcc/test_phone &amp;&amp; cp data/mfcc/test/cmvn.scp data/mfcc/test_phone || exit 1;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="词典构建"><a href="#词典构建" class="headerlink" title="词典构建"></a>词典构建</h3><p>这一块主要用于语言模型和语音解码，thchs30数据已经提取建好，主要包括3-gram的语言模型，和word-id之间的映射。</p>
<ul>
<li><p>词语言模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#prepare language stuff</span><br><span class="line">#build a large lexicon that invovles words in both the training and decoding.</span><br><span class="line">(</span><br><span class="line">  echo &quot;make word graph ...&quot;</span><br><span class="line">  cd $H; mkdir -p data/&#123;dict,lang,graph&#125; &amp;&amp; \</span><br><span class="line">  cp $thchs/resource/dict/&#123;extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt&#125; data/dict &amp;&amp; \</span><br><span class="line">  cat $thchs/resource/dict/lexicon.txt $thchs/data_thchs30/lm_word/lexicon.txt | \</span><br><span class="line">  grep -v &#x27;&lt;s&gt;&#x27; | grep -v &#x27;&lt;/s&gt;&#x27; | sort -u &gt; data/dict/lexicon.txt || exit 1;</span><br><span class="line">  utils/prepare_lang.sh --position_dependent_phones false data/dict &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang data/lang || exit 1;</span><br><span class="line">  gzip -c $thchs/data_thchs30/lm_word/word.3gram.lm &gt; data/graph/word.3gram.lm.gz || exit 1;</span><br><span class="line">  utils/format_lm.sh data/lang data/graph/word.3gram.lm.gz $thchs/data_thchs30/lm_word/lexicon.txt data/graph/lang || exit 1;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p>音素语言模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#make_phone_graph</span><br><span class="line">(</span><br><span class="line">  echo &quot;make phone graph ...&quot;</span><br><span class="line">  cd $H; mkdir -p data/&#123;dict_phone,graph_phone,lang_phone&#125; &amp;&amp; \</span><br><span class="line">  cp $thchs/resource/dict/&#123;extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt&#125; data/dict_phone  &amp;&amp; \</span><br><span class="line">  cat $thchs/data_thchs30/lm_phone/lexicon.txt | grep -v &#x27;&lt;eps&gt;&#x27; | sort -u &gt; data/dict_phone/lexicon.txt  &amp;&amp; \</span><br><span class="line">  echo &quot;&lt;SPOKEN_NOISE&gt; sil &quot; &gt;&gt; data/dict_phone/lexicon.txt  || exit 1;</span><br><span class="line">  utils/prepare_lang.sh --position_dependent_phones false data/dict_phone &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang_phone data/lang_phone || exit 1;</span><br><span class="line">  gzip -c $thchs/data_thchs30/lm_phone/phone.3gram.lm &gt; data/graph_phone/phone.3gram.lm.gz  || exit 1;</span><br><span class="line">  utils/format_lm.sh data/lang_phone data/graph_phone/phone.3gram.lm.gz $thchs/data_thchs30/lm_phone/lexicon.txt \</span><br><span class="line">    data/graph_phone/lang  || exit 1;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="模型训练-单因素-monophone-gt-三音素-tri-gt-LDA-x2F-MLLT-gt-SAT-gt-NN"><a href="#模型训练-单因素-monophone-gt-三音素-tri-gt-LDA-x2F-MLLT-gt-SAT-gt-NN" class="headerlink" title="模型训练(单因素(monophone)-&gt;三音素(tri)-&gt;LDA&#x2F;MLLT-&gt;SAT-&gt;NN)"></a>模型训练(单因素(monophone)-&gt;三音素(tri)-&gt;LDA&#x2F;MLLT-&gt;SAT-&gt;NN)</h3><p>我这只举monophone例子，后面都是一样，建议不要改动模型训练的顺序，前后有依赖。运行一次，全部训练完就行。<br>monophone用来训练单音子隐马尔科夫模型，一共进行40次迭代，每两次迭代进行一次对齐操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">steps/train_mono.sh --boost-silence 1.25 --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/mono || exit 1;</span><br><span class="line">#test monophone model</span><br><span class="line">local/thchs-30_decode.sh --mono true --nj $n &quot;steps/decode.sh&quot; exp/mono data/mfcc &amp;</span><br><span class="line"></span><br><span class="line">#monophone_ali</span><br><span class="line">steps/align_si.sh --boost-silence 1.25 --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/train data/lang exp/mono exp/mono_ali || exit 1;</span><br></pre></td></tr></table></figure>
<p>训练之后会有测试，给出模型的字错误率WER。直接<code>run.sh</code>就可以去睡觉了，等待脚本运行完成。<br>如何查看模型的WER错误率，可以到模型的目录下比如<code>exp/mono/decode_test_phone/scoring_kaldi</code>有个best_wer文件，里面记录了<code>%WER 32.49 [ 117586 / 361864, 16304 ins, 28325 del, 72957 sub ] exp/mono/decode_test_phone/wer_7_1.0</code></p>
<h2 id="训练后的模型如何使用"><a href="#训练后的模型如何使用" class="headerlink" title="训练后的模型如何使用"></a>训练后的模型如何使用</h2><p>这里参考<a target="_blank" rel="noopener" href="https://hesay.me/posts/kaldi_experience_2/">Kaldi初体验（二）：thchs30运行 - 他说</a></p>
<ul>
<li>从 <code>egs/voxforge</code> 把online_demo文件夹拷贝到 thchs30 下，和s5同级</li>
<li>在online_demo建online-data和work两个文件夹。online-data下建audio和models，models建tri1，audio放要识别的wav，可以自己放几个wav音频文件进去。</li>
<li>将s5下<code>exp/tri1</code>下的final.mdl和35.mdl拷贝到models目录下，把s5的<code>exp/tri1/graph_word</code>里面的words.txt和HCLG.fst也拷过去。其中，final.mdl是训练出来的模型，words.txt是字典，和HCLG.fst是有限状态机。</li>
<li>将<code>online-data/run.sh</code>中的<code>ac_model_type=tri2b_mmi</code>改为<code>ac_model_type=tri1</code></li>
<li>再做如下修改，其实就是将<code>$ac_model/final.mdl</code>改成了<code>$ac_model/final.mdl</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">online-wav-gmm-decode-faster --verbose=1 --rt-min=0.8 --rt-max=0.85\</span><br><span class="line">           --max-active=4000 --beam=12.0 --acoustic-scale=0.0769 \</span><br><span class="line">           scp:$decode_dir/input.scp $ac_model/model $ac_model/HCLG.fst \</span><br><span class="line">           $ac_model/words.txt &#x27;1:2:3:4:5&#x27; ark,t:$decode_dir/trans.txt \</span><br><span class="line">           ark,t:$decode_dir/ali.txt $trans_matrix;;</span><br><span class="line">改为</span><br><span class="line">online-wav-gmm-decode-faster --verbose=1 --rt-min=0.8 --rt-max=0.85\</span><br><span class="line">               --max-active=4000 --beam=12.0 --acoustic-scale=0.0769 \</span><br><span class="line">               scp:$decode_dir/input.scp $ac_model/final.mdl $ac_model/HCLG.fst \</span><br><span class="line">               $ac_model/words.txt &#x27;1:2:3:4:5&#x27; ark,t:$decode_dir/trans.txt \</span><br><span class="line">               ark,t:$decode_dir/ali.txt $trans_matrix;;</span><br></pre></td></tr></table></figure>
<p>之后直接运行<code>run.sh</code>就行，输出如下。暂时不知道WER咋会出现计算错误的问题。<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/491BAE97-2657-4217-9B1D-BC41B22734BE.png"></p>
<p>对于其他的模型使用大同小异，比如对于tri2b模型，除了上面那些文件外，还需要拷贝<code>12.mat</code>过去，然后修改两处地方。这里参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/AMDS123/article/details/70313744">基于kaldi的在线中文识别，online的操作介绍 - 人工智能 - CSDN博客</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#if [ -s $ac_model/matrix ]; then</span><br><span class="line">#    #trans_matrix=$ac_model/matrix</span><br><span class="line">#    trans_matrix=$ac_model/12.mat</span><br><span class="line">#fi</span><br><span class="line">trans_matrix=$ac_model/12.mat</span><br><span class="line"></span><br><span class="line">online-wav-gmm-decode-faster --verbose=1 --rt-min=0.8 --rt-max=0.85\</span><br><span class="line">            --max-active=4000 --beam=12.0 --acoustic-scale=0.0769 \</span><br><span class="line">            --left-context=3 --right-context=3 \</span><br><span class="line">            scp:$decode_dir/input.scp $ac_model/final.mdl $ac_model/HCLG.fst \</span><br><span class="line">            $ac_model/words.txt &#x27;1:2:3:4:5&#x27; ark,t:$decode_dir/trans.txt \</span><br><span class="line">            ark,t:$decode_dir/ali.txt $trans_matrix;;</span><br></pre></td></tr></table></figure>
<p>识别结果如下：<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/39CD292C-86FC-4CB7-8E2D-49EDF8437E19.png"><br>识别的准确率还是挺不高的，语音识别技术还是任重而道远，我就不掺和了。</p>
<p>遗留问题：如何使用训练出来DNN模型？<br>暂时没有解决，Kaldi的工具实在是太多了，复杂而不好用。</p>
<h2 id="如何在线解码（online）"><a href="#如何在线解码（online）" class="headerlink" title="如何在线解码（online）"></a>如何在线解码（online）</h2><p>online虽已经废弃，但实在好用，因此还是选择使用online模块进行在线解码。这里参考<a target="_blank" rel="noopener" href="https://www.twblogs.net/a/5b817aaa2b71772165acca52">kaldi - Online Audio Server（服務器客戶端建立方法-舊版在線解碼） - 台部落</a><br>这里主要采用online-audio-server-decode-faster进行在线解码，</p>
<p>server端：创建<code>run_server.sh</code>，然后copy下面代码进去，然后运行起来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">KALDI_ROOT=`pwd`/../../..</span><br><span class="line">echo $KALDI_ROOT</span><br><span class="line">export PATH=$PWD/../s5/utils/:$KALDI_ROOT/src/onlinebin:$KALDI_ROOT/src/bin:$PATH</span><br><span class="line"></span><br><span class="line">data_file=&quot;online-data&quot;</span><br><span class="line">ac_model_type=tri1</span><br><span class="line">ac_model=$&#123;data_file&#125;/models/$ac_model_type</span><br><span class="line"></span><br><span class="line">online-audio-server-decode-faster --verbose=1 --rt-min=0.5 --rt-max=3.0 \</span><br><span class="line">        --max-active=6000 --beam=72.0 --acoustic-scale=0.0769 \</span><br><span class="line">        $ac_model/final.mdl $ac_model/HCLG.fst \</span><br><span class="line">        $ac_model/words.txt &#x27;1:2:3:4:5&#x27; $ac_model/word_boundary.int 5010</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：这里有个<code>word_boundary.int </code>文件需要自己生成。将<code>run.sh</code>中的下面一行改一下，然后单独运行一下这个命令就行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#原指令：</span><br><span class="line">utils/prepare_lang.sh --position-dependent-phones false data/local/dict &quot;&lt;SPOKEN_NOISE&gt;&quot; \</span><br><span class="line">data/local/lang data/lang</span><br><span class="line">#改爲：</span><br><span class="line">utils/prepare_lang.sh data/local/dict &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang data/lang</span><br></pre></td></tr></table></figure>

<p>client端：创建<code>run_client.sh</code>，然后copy下面代码进去，路径啥的自己解决。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">KALDI_ROOT=`pwd`/../../..</span><br><span class="line">echo $KALDI_ROOT</span><br><span class="line">export PATH=$PWD/../s5/utils/:$KALDI_ROOT/src/onlinebin:$KALDI_ROOT/src/bin:$PATH</span><br><span class="line"></span><br><span class="line">data_file=&quot;online-data&quot;</span><br><span class="line">ac_model_type=tri1</span><br><span class="line">ac_model=$&#123;data_file&#125;/models/$ac_model_type</span><br><span class="line"></span><br><span class="line">online-audio-client  --htk --vtt localhost 5010 scp:/home/demo1/asr/kaldi/egs/thchs30/s5/data/test/example.scp</span><br></pre></td></tr></table></figure>

<p>这里面的example.scp是自己造的，可以在测试集上cp一些数据过来，格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">D32_990 /home/demo1/asr/kaldi/egs/thchs30/data/data_thchs30/test/D32_990.wav</span><br><span class="line">D32_991 /home/demo1/asr/kaldi/egs/thchs30/data/data_thchs30/test/D32_991.wav</span><br><span class="line">D32_992 /home/demo1/asr/kaldi/egs/thchs30/data/data_thchs30/test/D32_992.wav</span><br><span class="line">D32_993 /home/demo1/asr/kaldi/egs/thchs30/data/data_thchs30/test/D32_993.wav</span><br></pre></td></tr></table></figure>
<p>运行<code>run_client.sh</code>就可以看见实时解码的输出了。<br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/2C632BF4-4D66-4FA5-AB81-9A81A7501BE3.png"></p>
<p>一个问题：如何利用Kaldi构建可以供外部调用的API接口?<br>这是个麻烦的问题，我目前没有解决，想到的一个好的办法就是重写一下client端，使其支持远程调用。还是得吐槽kaldi的难用，不如自己从头用Python写一个。</p>
<h3 id="其它知识：openfst"><a href="#其它知识：openfst" class="headerlink" title="其它知识：openfst"></a>其它知识：openfst</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013569304/article/details/81560521">语音识别学习记录 kaldi中的openfst - emmmmmm - CSDN博客</a><br><img src="/2019/06/16/20190616_ASR_from_begin_to_abandoned/AB604857-18E2-44B9-B29D-659B23B88AF7.png"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>代码踩坑的问题就不总结了，主要总结一下我在探索kaldi时遇到的一些方法论上的问题。</p>
<ol>
<li>对语音识别调研不充分，没有形成一个全局的认识就开始搞kaldi，搞了一周后就懵逼了。然后才花了一些时间来重新认识语音识别，了解大致的过程，用到的技术等，这样才避免了被kaldi那繁多的脚本和生成的文件搞乱。做事的顺序不能颠倒了，方法不能错误。进入一个新的领域，没有正确的学习方法会绕很多路。</li>
<li>目标不明确，导致多走弯路，过分沉迷于测试不同的代码，想找到适合的那个，却忘了什么才是适合。这就像是走到了多个岔路口，每个都去试下，却忘记看岔路口上的标志。</li>
</ol>
</div><div class="tags"></div><div class="post-nav"><a class="pre" href="../../../08/26/20190826/">做AI，搞NLP，才有qian途</a><a class="next" href="../../../04/26/20190426_my-understand-of-AI/">谈谈我对AI的理解</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://example.com"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img src="/img/avatar.png"/></a><p>To be a better man.</p><a class="info-icon" href="https://twitter.com/username" title="Twitter" target="_blank" style="margin-inline:5px"> <i class="fa fa-twitter-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:admin@domain.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/username" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/AI/">AI</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/HBase/">HBase</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Hadoop/">Hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Hive/">Hive</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Nginx/">Nginx</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Spark%E7%B3%BB%E5%88%97/">Spark系列</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/ganglia/">ganglia</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/project/">project</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/tools/">tools</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0/">个人笔记</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E5%89%8D%E7%AB%AF/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0/">数据分析学习</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/">服务器</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/">架构设计</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E7%A7%9F%E6%88%BF%E7%B3%BB%E7%BB%9F/">租房系统</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="../../../../tags/HBase/" style="font-size: 15px;">HBase</a> <a href="../../../../tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="../../../../tags/Hive/" style="font-size: 15px;">Hive</a> <a href="../../../../tags/Spark/" style="font-size: 15px;">Spark</a> <a href="../../../../tags/Nginx/" style="font-size: 15px;">Nginx</a> <a href="../../../../tags/tools/" style="font-size: 15px;">tools</a> <a href="../../../../tags/JavaScript/" style="font-size: 15px;">JavaScript</a> <a href="../../../../tags/node/" style="font-size: 15px;">node</a> <a href="../../../../tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/" style="font-size: 15px;">服务器</a> <a href="../../../../tags/tornado/" style="font-size: 15px;">tornado</a> <a href="../../../../tags/%E5%A4%96%E5%8C%85/" style="font-size: 15px;">外包</a> <a href="../../../../tags/mongodb/" style="font-size: 15px;">mongodb</a> <a href="../../../../tags/%E7%A7%9F%E6%88%BF%E7%B3%BB%E7%BB%9F/" style="font-size: 15px;">租房系统</a> <a href="../../../../tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="../../../../2022/09/18/fuse/">fuse</a></li><li class="post-list-item"><a class="post-list-link" href="../../../12/01/20191201/">文本分类的一些总结</a></li><li class="post-list-item"><a class="post-list-link" href="../../../09/22/20190922/">第一次跳槽面试总结</a></li><li class="post-list-item"><a class="post-list-link" href="../../../09/05/20190905/">哲学家都干了些什么</a></li><li class="post-list-item"><a class="post-list-link" href="../../../09/01/20190901/">我准备离职了</a></li><li class="post-list-item"><a class="post-list-link" href="../../../08/26/20190826/">做AI，搞NLP，才有qian途</a></li><li class="post-list-item"><a class="post-list-link" href="">语音识别从入门到放弃</a></li><li class="post-list-item"><a class="post-list-link" href="../../../04/26/20190426_my-understand-of-AI/">谈谈我对AI的理解</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2018/08/06/SMP2018%E5%8F%82%E4%BC%9A%E8%A7%81%E9%97%BB/">SMP2018参会见闻</a></li><li class="post-list-item"><a class="post-list-link" href="../../../../2018/07/11/%E8%B8%8F%E5%85%A5%E7%A4%BE%E4%BC%9A%E8%BF%99%E4%B8%80%E5%B9%B4%E2%80%94%E2%80%94%E7%84%A6%E8%99%91%E7%9B%B8%E4%BC%B4/">踏入社会这一年——焦虑相伴</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="../../../../." rel="nofollow">xuxping.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="../../../../js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="../../../../js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="../../../../js/copycode.js?v=1.0.0" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="../../../../css/copycode.css?v=1.0.0"><script type="text/javascript" src="../../../../js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="../../../../js/smartresize.js?v=1.0.0"></script></div></body></html>